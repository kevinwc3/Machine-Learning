# -*- coding: utf-8 -*-
"""HouseLearn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pvwHf109RBH4gXTrI0derPhNktpaA8oo
"""

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn import tree
from sklearn.metrics import mean_squared_error
from imblearn.over_sampling import RandomOverSampler
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, r2_score
import altair as alt
from geopy.distance import geodesic
import math


df = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing.csv')

#df.head()

df.head()

crime = {'zipcode': [98038,98023,98116,98117,98034,98065,98031,98075,98028,98103,98004,
                     98166,98077,98008,98006,98199,98052,98136,98108,98055,98027,98058,
                     98144,98115,98168,98102,98042,98059,98002,98155,98072,98001,98112,
                     98007,98177,98074,98119,98011,98014,98106,98045,98033,98125,98133,
                     98053,98122,98022,98178,98148,98019,98010,98070,98056,98030,98188,
                     98029,98107,98105,98198,98003,98118,98126,98040,98092,98032,98146,
                     98024,98005,98039,98109],
         'crime_rate': [1444.9,5952.9,6127.3,6127.3,2363.2,1246.1,4961.2,756.6,1379.9,
                        6127.3,1282.1,4723.2,3839.4,3400.5,3053,6127.3,2992.6,4723.2,
                        1525.8,5300.3,3139.2,5300.3,6127.3,947,16575.5,6127.3,3833.7,
                        3053,6022.1,2558.9,3839.4,2695.8,6127.3,3400.5,3050.4,756.6,
                        6127.3,3037.1,966.3,4723.2,3974.8,2363.2,2558.9,3050.4,2992.6,
                        6127.3,3119.9,16575.5,5348.4,966.3,1063.6,2042.4,3053,4961.2,
                        5348.4,3139.2,6127.3,6127.3,3728.3,5952.9,1525.8,6127.3,1525.8,
                        6022.1,3728.3,4723.2,1246.1,3400.5,2216.6,6127.3],
         'median_household_income': [95043,67906,74274,86986,77688,121415,63709,142926,
                                     82448,75763,93521,63320,137125,92986,110290,82882,
                                     99192,84344,52232,66461,100644,77780,55950,84159,
                                     49233,65054,87342,91465,43568,72281,107654,71746,
                                     96054,73162,95648,143686,68383,71720,95394,57875,
                                     88906,103250,53044,51499,116518,53570,66295,58707,
                                     45424,95025,85398,72774,70683,51446,40815,99974,
                                     67566,45560,56364,45894,52276,66408,126359,70877,
                                     48853,56809,93777,84774,183833,77034]}



crime_df = pd.DataFrame(crime)
df = df.merge(crime_df,on='zipcode',how='left')

df['since_renovation'] = np.where(df['yr_renovated'] == 0, 2015 - df['yr_built'], 2015 - df['yr_renovated'])
df['bedrooms'] = np.where(df['bedrooms'] > 30, df['bathrooms'],df['bedrooms'])
df = df[df['sqft_living'] < 13000]

y = df['price']
X = df.drop(columns=['price','id','zipcode','yr_renovated'])


X['date'] = pd.to_datetime(X['date'])
#X['zipcode'] = X['zipcode'].astype('category')
X = pd.get_dummies(X, drop_first=True)
X['date'] = X['date'].astype('datetime64[s]').astype(int)


scaler = MinMaxScaler()
for col in X:
  X[col] = scaler.fit_transform(X[ [col] ])

X.head()
#df.head()

best_result = 200000
best_lambda = 0
lambda_list = []
result_list = []
for i in range(1,10,1):
  i /= 10
  X_train, X_other, y_train, y_other = train_test_split(X, y, test_size=0.20, random_state=44)
  X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, test_size=0.50, random_state=44)
  xgb = XGBRegressor(random_state=44,reg_lambda=57,n_estimators=740, learning_rate=.12,subsample=.78,alpha=i)
  xgb.fit(X_train,y_train)
  predictions = xgb.predict(X_test)
  result = mean_squared_error(y_test, predictions, squared=False)
  lambda_list.append(i)
  result_list.append(result)
  if result < best_result:
    best_result = result
    best_lambda = i

#print(best_result)
#print(best_lambda)
lambda_df = pd.DataFrame(
    {'learning rate': lambda_list,
     'rmse': result_list
     })
alt.Chart(lambda_df).mark_line().encode(
    x='learning rate',
    y='rmse'
)

X_train, X_other, y_train, y_other = train_test_split(X, y, test_size=0.20, random_state=44)
X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, test_size=0.50, random_state=44)
xgb = XGBRegressor(random_state=44,reg_lambda=57,n_estimators=740, learning_rate=.12,subsample=.78) #Default Best: max_depth,alpha,scale_pos_weight,max_bin,max_leaves,num_parallel_tree,eta
xgb.fit(X_train,y_train)
predictions = xgb.predict(X_test)
result = mean_squared_error(y_test, predictions, squared=False)
print(result)

r = r2_score(y_test,predictions)
print(r)

columns = X.columns.tolist()
feature_importances_one = np.around(xgb.feature_importances_,4)
feature_importance_one = pd.DataFrame({'Feature': columns, 'Importance': feature_importances_one})
feature_importance_one = feature_importance_one.sort_values(by='Importance', ascending=False)
#print(feature_importance_one)
top_importance = feature_importance_one.head()
top_importance
import altair as alt
alt.Chart(top_importance,title='Most Important Features').mark_bar().encode(
    x='Feature',
    y='Importance'
).properties(
    width=200,
    height=350
)

predictions = xgb.predict(X_val)
result = mean_squared_error(y_val, predictions, squared=False)
print(result)

import altair as alt
box = abs(predictions - y_test) / y_test
box_list = box.to_list()
y_list = y_test.to_list()
data = {'Percent Off': box_list,'Home Prices': y_list, 'Predictions': predictions}
box_df = pd.DataFrame(data)
box_df.sort_values('Percent Off',ascending=False).head()
alt.Chart(box_df,title='How off were our predictions?').mark_boxplot(size=100).encode(
    y="Percent Off"
).properties(
    width=200,
    height=400
)

y_df = pd.DataFrame(y).query('price > 1000000')

y_df.sort_values('price',ascending=False)

final_df = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing_holdout_test.csv')
crime = {'zipcode': [98038,98023,98116,98117,98034,98065,98031,98075,98028,98103,98004,
                     98166,98077,98008,98006,98199,98052,98136,98108,98055,98027,98058,
                     98144,98115,98168,98102,98042,98059,98002,98155,98072,98001,98112,
                     98007,98177,98074,98119,98011,98014,98106,98045,98033,98125,98133,
                     98053,98122,98022,98178,98148,98019,98010,98070,98056,98030,98188,
                     98029,98107,98105,98198,98003,98118,98126,98040,98092,98032,98146,
                     98024,98005,98039,98109],
         'crime_rate': [1444.9,5952.9,6127.3,6127.3,2363.2,1246.1,4961.2,756.6,1379.9,
                        6127.3,1282.1,4723.2,3839.4,3400.5,3053,6127.3,2992.6,4723.2,
                        1525.8,5300.3,3139.2,5300.3,6127.3,947,16575.5,6127.3,3833.7,
                        3053,6022.1,2558.9,3839.4,2695.8,6127.3,3400.5,3050.4,756.6,
                        6127.3,3037.1,966.3,4723.2,3974.8,2363.2,2558.9,3050.4,2992.6,
                        6127.3,3119.9,16575.5,5348.4,966.3,1063.6,2042.4,3053,4961.2,
                        5348.4,3139.2,6127.3,6127.3,3728.3,5952.9,1525.8,6127.3,1525.8,
                        6022.1,3728.3,4723.2,1246.1,3400.5,2216.6,6127.3],
         'median_household_income': [95043,67906,74274,86986,77688,121415,63709,142926,
                                     82448,75763,93521,63320,137125,92986,110290,82882,
                                     99192,84344,52232,66461,100644,77780,55950,84159,
                                     49233,65054,87342,91465,43568,72281,107654,71746,
                                     96054,73162,95648,143686,68383,71720,95394,57875,
                                     88906,103250,53044,51499,116518,53570,66295,58707,
                                     45424,95025,85398,72774,70683,51446,40815,99974,
                                     67566,45560,56364,45894,52276,66408,126359,70877,
                                     48853,56809,93777,84774,183833,77034]}



crime_df = pd.DataFrame(crime)
final_df = final_df.merge(crime_df,on='zipcode',how='left')

final_df['since_renovation'] = np.where(final_df['yr_renovated'] == 0, 2015 - final_df['yr_built'], 2015 - final_df['yr_renovated'])
final_df['bedrooms'] = np.where(final_df['bedrooms'] > 30, final_df['bathrooms'],final_df['bedrooms'])
final_df = final_df[final_df['sqft_living'] < 13000]

X = final_df.drop(columns=['id','zipcode','yr_renovated'])


X['date'] = pd.to_datetime(X['date'])
#X['zipcode'] = X['zipcode'].astype('category')
X = pd.get_dummies(X, drop_first=True)
X['date'] = X['date'].astype('datetime64[s]').astype(int)


# scaler = MinMaxScaler()
for col in X:
  X[col] = scaler.transform(X[ [col] ])

X.head()

predictions = xgb.predict(X)
predictions_df = pd.DataFrame(predictions)
predictions_df.to_csv('housing_predictions.csv')
final_df

import altair as alt
alt.data_transformers.disable_max_rows()
alt.Chart(df).mark_boxplot().encode(
    y='price'
)